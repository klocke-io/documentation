import{_ as o,c as t,o as r,a2 as a}from"./chunks/framework.B8WFj13S.js";const s="/documentation/pr-preview/pr-2/assets/core-components.rR3dM6qJ.png",n="/documentation/pr-preview/pr-2/assets/control-plane-components.bhf7WZdL.png",i="/documentation/pr-preview/pr-2/assets/access-plutono.DYXGp0Q_.png",l="/documentation/pr-preview/pr-2/assets/welcome-plutono.BeiPJO38.png",p="/documentation/pr-preview/pr-2/assets/plutono.DQ_4FqJB.png",c="/documentation/pr-preview/pr-2/assets/prometheus.D4wnAMiZ.png",d="/documentation/pr-preview/pr-2/assets/prometheus-plutono.CU97urTQ.png",h="/documentation/pr-preview/pr-2/assets/explore-loki.BvvWd35q.png",u="/documentation/pr-preview/pr-2/assets/select-vali.BcsrP1Kg.png",m="/documentation/pr-preview/pr-2/assets/vali-logs.C6rZbod-.png",g="/documentation/pr-preview/pr-2/assets/data-flow-logging.CeDEQQia.png",f="/documentation/pr-preview/pr-2/assets/data-flow-monitoring-1.D0rGpLp8.png",b="/documentation/pr-preview/pr-2/assets/data-flow-monitoring-2.C64lZyFr.png",w="/documentation/pr-preview/pr-2/assets/data-flow-monitoring-3.ze5ez7br.png",C=JSON.parse('{"title":"Components","description":"","frontmatter":{"github_repo":"https://github.com/gardener/documentation","github_subdir":"website/documentation/getting-started/observability","params":{"github_branch":"master"},"path_base_for_github_subdir":{"from":"content/docs/getting-started/observability/components.md","to":"components.md"},"title":"Components","weight":1,"prev":false,"next":false},"headers":[],"relativePath":"docs/getting-started/observability/components/index.md","filePath":"docs/getting-started/observability/components.md","lastUpdated":null}'),v={name:"docs/getting-started/observability/components/index.md"};function y(k,e,_,P,q,x){return r(),t("div",null,e[0]||(e[0]=[a('<h1 id="components" tabindex="-1">Components <a class="header-anchor" href="#components" aria-label="Permalink to &quot;Components&quot;">​</a></h1><h2 id="core-components" tabindex="-1">Core Components <a class="header-anchor" href="#core-components" aria-label="Permalink to &quot;Core Components&quot;">​</a></h2><p><img src="'+s+'" alt="core-components"></p><p>The core Observability components which Gardener offers out-of-the-box are:</p><ul><li>Prometheus - for Metrics and Alerting</li><li>Vali - a Loki fork for Logging</li><li>Plutono - a Grafana fork for Dashboard visualization</li></ul><p>Both forks are done from the last version with an Apache license.</p><h3 id="control-plane-components-on-the-seed" tabindex="-1">Control Plane Components on the Seed <a class="header-anchor" href="#control-plane-components-on-the-seed" aria-label="Permalink to &quot;Control Plane Components on the Seed&quot;">​</a></h3><p><img src="'+n+'" alt="control-plane-components"></p><p>Prometheus, Plutono, and Vali are all located in the seed cluster. They run next to the control plane of your cluster.</p><p>The next sections will explore those components in detail.</p><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p>Gardener only provides monitoring for Gardener-deployed components. If you need logging or monitoring for your workload, then you need to deploy your own monitoring stack into your shoot cluster.</p></div><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p>Gardener only provides a monitoring stack if the cluster is not of <code>purpose: testing</code>. For more information, see <a href="https://gardener.cloud/docs/gardener/shoot_purposes/" target="_blank" rel="noreferrer">Shoot Cluster Purpose</a>.</p></div><h3 id="logging-into-plutono" tabindex="-1">Logging into Plutono <a class="header-anchor" href="#logging-into-plutono" aria-label="Permalink to &quot;Logging into Plutono&quot;">​</a></h3><p>Let us start by giving some visual hints on how to access Plutono. <a href="https://github.com/credativ/plutono#plutono" target="_blank" rel="noreferrer">Plutono</a> allows us to query logs and metrics and visualize those in form of dashboards. Plutono is shipped ready-to-use with a Gardener shoot cluster.</p><p>In order to access the Gardener provided dashboards, open the <code>Plutono</code> link provided in the Gardener dashboard. You will be automatically logged in through OIDC based authentication:</p><p><img src="'+i+'" alt="access-plutono"></p><p>Access is still possible via the non-OIDC ingress using the credentials from the <code>&lt;clustername&gt;.monitoring</code> secret. It contains the HTTP basic auth credentials in base64-encoded form, as well as the Plutono ingress URL. The Plutono URL is present as an annotation on the <code>.monitoring</code> secret. It can be fetched with <code>kubectl get secret &lt;clustername&gt;.monitoring -o jsonpath=&quot;{.metadata.annotations.url}&quot;</code>. The Prometheus URL can be derived from the Plutono URL by replacing the <code>gu</code> prefix with <code>p</code>.</p><h3 id="accessing-the-dashboards" tabindex="-1">Accessing the Dashboards <a class="header-anchor" href="#accessing-the-dashboards" aria-label="Permalink to &quot;Accessing the Dashboards&quot;">​</a></h3><p>After logging in, you will be greeted with a Plutono welcome screen. Navigate to <code>General/Home</code>, as depicted with the red arrow in the next picture:</p><p><img src="'+l+'" alt="welcome-plutono"></p><p>Then you will be able to select the dashboards. Some interesting ones to look at are:</p><ul><li>The <code>Kubernetes Control Plane Status</code> dashboard allows you to check control plane availability during a certain time frame.</li><li>The <code>API Server</code> dashboard gives you an overview on which requests are done towards your apiserver and how long they take.</li><li>With the <code>Node Details</code> dashboard you can analyze CPU/Network pressure or memory usage for nodes.</li><li>The <code>Network Problem Detector</code> dashboard illustrates the results of periodic networking checks between nodes and to the APIServer.</li></ul><p>Here is a picture with the <code>Kubernetes Control Plane Status</code> dashboard.</p><p><img src="'+p+'" alt="plutono"></p><h3 id="prometheus" tabindex="-1">Prometheus <a class="header-anchor" href="#prometheus" aria-label="Permalink to &quot;Prometheus&quot;">​</a></h3><p><a href="https://prometheus.io/" target="_blank" rel="noreferrer">Prometheus</a> is a monitoring system and a time series database. It can be queried using PromQL, the so called Prometheus Querying Language.</p><p><img src="'+c+'" alt="prometheus"></p><p>This example query describes the current uptime status of the kube apiserver.</p><h4 id="prometheus-and-plutono" tabindex="-1">Prometheus and Plutono <a class="header-anchor" href="#prometheus-and-plutono" aria-label="Permalink to &quot;Prometheus and Plutono&quot;">​</a></h4><p>Time series data from Prometheus can be made visible with Plutono. Here we see how the query above which describes the uptime of a Kubernetes cluster is visualized with a Plutono dashboard.</p><p><img src="'+d+'" alt="prometheus-plutono"></p><h3 id="vali-logs-via-plutono" tabindex="-1">Vali Logs via Plutono <a class="header-anchor" href="#vali-logs-via-plutono" aria-label="Permalink to &quot;Vali Logs via Plutono&quot;">​</a></h3><p>Vali is our logging solution. In order to access the logs provided by Vali, you need to:</p><ol><li><p><a href="/documentation/pr-preview/pr-2/docs/getting-started/observability/components/#logging-into-plutono">Log into Plutono</a>.</p></li><li><p>Choose <code>Explore</code>, which is depicted as the little compass symbol:</p></li></ol><p><img src="'+h+'" alt="explore-loki"></p><ol><li>Select <code>Vali</code> at the top left, as shown here:</li></ol><p><img src="'+u+'" alt="select-vali"></p><p>There you can browse logs or events of the control plane components.</p><p><img src="'+m+'" alt="vali-logs"></p><p>Here are some examples of helpful queries:</p><ul><li><code>{container_name=&quot;cluster-autoscaler&quot; }</code> to get cluster-autoscaler logs and see why certain node groups were scaled up.</li><li><code>{container_name=&quot;kube-apiserver&quot;} |~ &quot;error&quot;</code> to get the logs of the kube-apiserver container and filter for errors.</li><li><code>{unit=&quot;kubelet.service&quot;, nodename=&quot;ip-123&quot;}</code> to get the kubelet logs of a specific node.</li><li><code>{unit=&quot;containerd.service&quot;, nodename=&quot;ip-123&quot;}</code> to retrieve the containerd logs for a specific node.</li></ul><p>Choose <code>Help &gt;</code> in order to see what options exist to filter the results.</p><p>For more information on how to retrieve K8s events from the past, see <a href="/documentation/pr-preview/pr-2/docs/gardener/observability/logging/#how-to-access-the-logs">How to Access Logs</a>.</p><h2 id="detailed-view" tabindex="-1">Detailed View <a class="header-anchor" href="#detailed-view" aria-label="Permalink to &quot;Detailed View&quot;">​</a></h2><h3 id="data-flow" tabindex="-1">Data Flow <a class="header-anchor" href="#data-flow" aria-label="Permalink to &quot;Data Flow&quot;">​</a></h3><p>Our monitoring and logging solutions Vali and Prometheus both run next to the control plane of the shoot cluster.</p><h4 id="data-flow-logging" tabindex="-1">Data Flow - Logging <a class="header-anchor" href="#data-flow-logging" aria-label="Permalink to &quot;Data Flow - Logging&quot;">​</a></h4><p>The following diagram allows a more detailed look at Vali and the data flow.</p><p><img src="'+g+'" alt="data-flow-logging"></p><p>On the very left, we see Plutono as it displays the logs. Vali is aggregating the logs from different sources.</p><p>Valitail and Fluentbit send the logs to Vali, which in turn stores them.</p><p><em>Valitail</em></p><p>Valitail is a systemd service that runs on each node. It scrapes kubelet, containerd, kernel logs, and the logs of the pods in the kube-system namespace.</p><p><em>Fluentbit</em></p><p>Fluentbit runs as a daemonset on each seed node. It scrapes logs of the kubernetes control plane components, like apiserver or etcd.</p><p>It also scrapes logs of the Gardener deployed components which run next to the control plane of the cluster, like the machine-controller-manager or the cluster autoscaler. Debugging those components, for example, would be helpful when finding out why certain worker groups got scaled up or why nodes were replaced.</p><h4 id="data-flow-monitoring" tabindex="-1">Data Flow - Monitoring <a class="header-anchor" href="#data-flow-monitoring" aria-label="Permalink to &quot;Data Flow - Monitoring&quot;">​</a></h4><p>Next to each shoot&#39;s control plane, we deploy an instance of Prometheus in the seed.</p><p>Gardener uses <a href="https://prometheus.io/" target="_blank" rel="noreferrer">Prometheus</a> for storing and accessing shoot-related metrics and alerting.</p><p>The diagram below shows the data flow of metrics. Plutono uses PromQL queries to query data from Prometheus. It then visualises those metrics in dashboards. Prometheus itself scrapes various targets for metrics, as seen in the diagram below by the arrows pointing to the Prometheus instance.</p><p><img src="'+f+'" alt="data-flow-monitoring-1"></p><p>Let us have a look what metrics we scrape for debugging purposes:</p><p><strong>Container performance metrics</strong></p><p>cAdvisor is an open-source agent integrated into the kubelet binary that monitors resource usage and analyzes the performance of containers. It collects statistics about the CPU, memory, file, and network usage for all containers running on a given node. We use it to scrape data for all pods running in the kube-system namespace in the shoot cluster.</p><p><strong>Hardware and kernel-related metrics</strong></p><p>The <a href="https://prometheus.io/docs/guides/node-exporter/" target="_blank" rel="noreferrer">Prometheus Node Exporter</a> runs as a daemonset in the kube-system namespace of your shoot cluster. It exposes a wide variety of hardware and kernel-related metrics. Some of the metrics we scrape are, for example, the current usage of the filesystem (<code>node_filesystem_free_bytes</code>) or current CPU usage (<code>node_cpu_seconds_total</code>). Both can help you identify if nodes are running out of hardware resources, which could lead to your workload experiencing downtimes.</p><p><strong>Control plane component specific metrics</strong></p><p>The different control plane pods (for example, etcd, API server, and kube-controller-manager) emit metrics over the <code>/metrics</code> endpoint. This includes metrics like how long webhooks take, the request count of the apiserver and storage information, like how many and what kind of objects are stored in etcd.</p><p><strong>Metrics about the state of Kubernetes objects</strong></p><p><a href="https://github.com/kubernetes/kube-state-metrics" target="_blank" rel="noreferrer">kube-state-metrics</a> is a simple service that listens to the Kubernetes API server and generates metrics about the state of the objects. It is not concerned with metrics about the Kubernetes components, but rather it exposes metrics calculated from the status of Kubernetes objects (for example, resource requests or health of pods).</p><p>In the following image a few example metrics, which are exposed by the various components, are listed: <img src="'+b+'" alt="data-flow-monitoring-2"></p><p>We only store metrics for Gardener deployed components. Those include the Kubernetes control plane, Gardener managed system components (e.g., pods) in the kube-system namespace of the shoot cluster or systemd units on the nodes. We do not gather metrics for workload deployed in the shoot cluster. This is also shown in the picture below.</p><p>This means that for any workload you deploy into your shoot cluster, you need to deploy monitoring and logging yourself.</p><p>Logs or metrics are kept up to 14 days or when a configured space limit is reached.</p><p><img src="'+w+'" alt="data-flow-monitoring-3"></p>',75)]))}const D=o(v,[["render",y]]);export{C as __pageData,D as default};
