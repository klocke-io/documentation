import{_ as n,c as r,o as t,a2 as a}from"./chunks/framework.B8WFj13S.js";const p=JSON.parse('{"title":"Fine-Tuning kube-proxy Readiness: Ensuring Accurate Health Checks During Node Scale-Down","description":"","frontmatter":{"aliases":["/blog/2025/05/21/fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down"],"authors":[{"avatar":"https://avatars.githubusercontent.com/ScheererJ","email":"johannes.scheerer@sap.com","login":"ScheererJ","name":"Johannes Scheerer"}],"github_repo":"https://github.com/gardener/documentation","github_subdir":"website/blog/2025/05","linkTitle":"Fine-Tuning kube-proxy Readiness: Ensuring Accurate Health Checks During Node Scale-Down","newsSubtitle":"May 21, 2025","params":{"github_branch":"master"},"path_base_for_github_subdir":{"from":"content/blog/2025/05/05-21-fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down.md","to":"05-21-fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down.md"},"publishdate":"2025-05-21","title":"Fine-Tuning kube-proxy Readiness: Ensuring Accurate Health Checks During Node Scale-Down"},"headers":[],"relativePath":"blog/2025/05/05-21-fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down/index.md","filePath":"blog/2025/05/05-21-fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down.md","lastUpdated":null}'),o={name:"blog/2025/05/05-21-fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down/index.md"};function s(i,e,d,c,l,u){return t(),r("div",null,e[0]||(e[0]=[a('<h1 id="fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down" tabindex="-1">Fine-Tuning kube-proxy Readiness: Ensuring Accurate Health Checks During Node Scale-Down <a class="header-anchor" href="#fine-tuning-kube-proxy-readiness-ensuring-accurate-health-checks-during-node-scale-down" aria-label="Permalink to &quot;Fine-Tuning kube-proxy Readiness: Ensuring Accurate Health Checks During Node Scale-Down&quot;">​</a></h1><p>Gardener has recently refined how it determines the readiness of <code>kube-proxy</code> components within managed Kubernetes clusters. This adjustment leads to more accurate system health reporting, especially during node scale-down operations orchestrated by <code>cluster-autoscaler</code>.</p><h3 id="the-challenge-kube-proxy-readiness-during-node-scale-down" tabindex="-1">The Challenge: kube-proxy Readiness During Node Scale-Down <a class="header-anchor" href="#the-challenge-kube-proxy-readiness-during-node-scale-down" aria-label="Permalink to &quot;The Challenge: kube-proxy Readiness During Node Scale-Down&quot;">​</a></h3><p>Previously, Gardener utilized <code>kube-proxy</code>&#39;s <code>/healthz</code> endpoint for its readiness probe. While generally effective, this endpoint&#39;s behavior changed in Kubernetes 1.28 (as part of <a href="https://github.com/alexanderConstantinescu/kubernetes-enhancements/blob/e3d8adae9cf79338add2149db0900e47a4c64338/keps/sig-network/3836-kube-proxy-improved-ingress-connectivity-reliability/README.md?plain=1#L105-L107" target="_blank" rel="noreferrer">KEP-3836</a> and implemented in <a href="https://github.com/kubernetes/kubernetes/pull/116470" target="_blank" rel="noreferrer">kubernetes/kubernetes#116470</a>). The <code>/healthz</code> endpoint now reports <code>kube-proxy</code> as unhealthy if its node is marked for deletion by <code>cluster-autoscaler</code> (e.g., via a specific taint) or has a deletion timestamp.</p><p>This behavior is intended to help external load balancers (particularly those using <code>externalTrafficPolicy: Cluster</code> on infrastructures like GCP) avoid sending <em>new</em> traffic to nodes that are about to be terminated. However, for Gardener&#39;s internal system component health checks, this meant that <code>kube-proxy</code> could appear unready for extended periods if node deletion was delayed due to <code>PodDisruptionBudgets</code> or long <code>terminationGracePeriodSeconds</code>. This could lead to misleading &quot;unhealthy&quot; states for the cluster&#39;s system components.</p><h3 id="the-solution-aligning-with-upstream-kube-proxy-enhancements" tabindex="-1">The Solution: Aligning with Upstream kube-proxy Enhancements <a class="header-anchor" href="#the-solution-aligning-with-upstream-kube-proxy-enhancements" aria-label="Permalink to &quot;The Solution: Aligning with Upstream kube-proxy Enhancements&quot;">​</a></h3><p>To address this, Gardener now leverages the <code>/livez</code> endpoint for <code>kube-proxy</code>&#39;s readiness probe in clusters running Kubernetes version 1.28 and newer. The <code>/livez</code> endpoint, also introduced as part of the aforementioned <code>kube-proxy</code> improvements, checks the actual liveness of the <code>kube-proxy</code> process itself, without considering the node&#39;s termination status.</p><p>For clusters running Kubernetes versions 1.27.x and older (where <code>/livez</code> is not available), Gardener will continue to use the <code>/healthz</code> endpoint for the readiness probe.</p><p>This change, detailed in <a href="https://github.com/gardener/gardener/pull/12015" target="_blank" rel="noreferrer">gardener/gardener#12015</a>, ensures that Gardener&#39;s readiness check for <code>kube-proxy</code> accurately reflects <code>kube-proxy</code>&#39;s operational status rather than the node&#39;s lifecycle state. It&#39;s important to note that this adjustment does not interfere with the goals of KEP-3836; cloud controller managers can still utilize the <code>/healthz</code> endpoint for their load balancer health checks as intended.</p><h3 id="benefits-for-gardener-operators" tabindex="-1">Benefits for Gardener Operators <a class="header-anchor" href="#benefits-for-gardener-operators" aria-label="Permalink to &quot;Benefits for Gardener Operators&quot;">​</a></h3><p>This enhancement brings a key benefit to Gardener operators:</p><ul><li><strong>More Accurate System Health:</strong> The system components health check will no longer report <code>kube-proxy</code> as unhealthy simply because its node is being gracefully terminated by <code>cluster-autoscaler</code>. This reduces false alarms and provides a clearer view of the cluster&#39;s actual health.</li><li><strong>Smoother Operations:</strong> Operations teams will experience fewer unnecessary alerts related to <code>kube-proxy</code> during routine scale-down events, allowing them to focus on genuine issues.</li></ul><p>By adapting its <code>kube-proxy</code> readiness checks, Gardener continues to refine its operational robustness, providing a more stable and predictable management experience.</p><h3 id="further-information" tabindex="-1">Further Information <a class="header-anchor" href="#further-information" aria-label="Permalink to &quot;Further Information&quot;">​</a></h3><ul><li><strong>GitHub Pull Request:</strong> <a href="https://github.com/gardener/gardener/pull/12015" target="_blank" rel="noreferrer">gardener/gardener#12015</a></li><li><strong>Recording of the presentation segment:</strong> <a href="https://youtu.be/ssvXpPliOY0?t=1151" target="_blank" rel="noreferrer">Watch on YouTube (starts at the relevant section)</a></li><li><strong>Upstream KEP:</strong> <a href="https://github.com/alexanderConstantinescu/kubernetes-enhancements/blob/e3d8adae9cf79338add2149db0900e47a4c64338/keps/sig-network/3836-kube-proxy-improved-ingress-connectivity-reliability/README.md?plain=1#L105-L107" target="_blank" rel="noreferrer">KEP-3836: Kube-proxy improved ingress connectivity reliability</a></li><li><strong>Upstream Kubernetes PR:</strong> <a href="https://github.com/kubernetes/kubernetes/pull/116470" target="_blank" rel="noreferrer">kubernetes/kubernetes#116470</a></li></ul>',15)]))}const g=n(o,[["render",s]]);export{p as __pageData,g as default};
